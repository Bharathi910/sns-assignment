{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Statement 1: Natural Language Processing (NLP)**"
      ],
      "metadata": {
        "id": "GvUTiNnYRXVl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ivt9xdmEamSm"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download resources\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uva1QpHEbP-K",
        "outputId": "1e5de136-0a99-41d6-d830-f562369bb411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Spacy model\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "3l3ajpTNbT4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocesses and tokenizes input text.\n",
        "def preprocess_and_tokenize(text):\n",
        "  if not isinstance(text, str):# Check for non-string inputs\n",
        "        raise ValueError(\"Input must be a string\")\n",
        "  text = text.lower()\n",
        "  text = ''.join([char for char in text if char not in punctuation])# Remove punctuation\n",
        "  doc = nlp(text)# Tokenize using spaCy\n",
        "  # Remove stop words and non-alphabetic tokens\n",
        "  tokens = [token.lemma_ for token in doc if token.text not in stop_words and token.is_alpha]\n",
        "\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "qtYBu71LbXdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Example\n",
        "text = \"A computer is a machine that can store and process information. Most computers rely on a binary system, which uses two variables, 0 and 1, to complete tasks such as storing data, calculating algorithms, and displaying information.\"\n",
        "tokens = preprocess_and_tokenize(text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdtrSF2pb14N",
        "outputId": "e9beb6bf-ab83-45b8-be1c-99eb9117397a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['computer', 'machine', 'store', 'process', 'information', 'computer', 'rely', 'binary', 'system', 'use', 'two', 'variable', 'complete', 'task', 'store', 'datum', 'calculate', 'algorithm', 'display', 'information']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Statement 2: Text Generation**"
      ],
      "metadata": {
        "id": "-KlzY91PR0Nr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pipeline function from the Hugging Face transformers library\n",
        "from transformers import pipeline\n",
        "# Create a text generation pipeline using a pre-trained model 'distilgpt2'\n",
        "# 'distilgpt2' is a smaller and faster variant of GPT-2\n",
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "# Use the text generator to produce two sequences of text based on the provided prompt\n",
        "generator(\"I will like to\", max_length=50, num_return_sequences=2)\n"
      ],
      "metadata": {
        "id": "U3O4Lc7lh19z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c990a75a-38ab-43cf-b151-e2d1ea230a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'I will like to thank the guys we have come through and we are always impressed with them to a large extent.'},\n",
              " {'generated_text': 'I will like to express my opinion that when the Supreme Court is set through the courts we are able to get the justice who will lead the whole nation in this Court.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Statement 3: Prompt Engineering**"
      ],
      "metadata": {
        "id": "hsm0XagfR-8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from datasets import load_metric\n",
        "\n",
        "# Load the QA model and ROUGE metric\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "rouge = load_metric(\"rouge\")\n",
        "\n",
        "# Updated context about machine learning\n",
        "context = \"\"\"\n",
        "Machine learning is a field of artificial intelligence that focuses on the development of algorithms that enable computers to learn from and make predictions based on data. It encompasses a range of techniques, including supervised learning, unsupervised learning, and reinforcement learning. Supervised learning involves training a model on labeled data, while unsupervised learning involves finding hidden patterns in unlabeled data. Reinforcement learning is based on the idea of learning through trial and error, where an agent learns to make decisions by receiving rewards or penalties. Machine learning has applications in various domains such as healthcare, finance, and autonomous vehicles.\n",
        "\"\"\"\n",
        "\n",
        "questions = [\n",
        "    \"What are the main techniques used in machine learning?\",\n",
        "    \"How does supervised learning differ from unsupervised learning?\",\n",
        "    \"What is the purpose of reinforcement learning?\"\n",
        "]\n",
        "\n",
        "# Different prompt designs\n",
        "prompts = [\n",
        "    \"Based on the context, answer the following question:\",\n",
        "    \"Using the provided context, respond to this question:\",\n",
        "    \"Given the context, what is the answer to the question below?\"\n",
        "]\n",
        "\n",
        "# Generate answers for each prompt\n",
        "answers = []\n",
        "for question in questions:\n",
        "    for prompt in prompts:\n",
        "        full_prompt = prompt + \"\\n\" + question\n",
        "        result = qa_pipeline(question=full_prompt, context=context)\n",
        "        answer = result['answer']\n",
        "        answers.append((question, prompt, answer))\n",
        "        print(f\"Question: {question}\\nPrompt: {prompt}\\nAnswer: {answer}\\n\")\n",
        "\n",
        "# Reference answers for evaluation (using known correct answers)\n",
        "reference_answers = [\n",
        "    \"Machine learning techniques include supervised learning, unsupervised learning, and reinforcement learning.\",\n",
        "    \"Supervised learning involves training on labeled data, while unsupervised learning involves finding patterns in unlabeled data.\",\n",
        "    \"Reinforcement learning involves learning through trial and error by receiving rewards or penalties.\"\n",
        "]\n",
        "\n",
        "# Prepare data for evaluation\n",
        "predictions = [a[2] for a in answers]\n",
        "references = [[reference] for reference in reference_answers]\n",
        "\n",
        "# Evaluate using ROUGE\n",
        "rouge_scores = [rouge.compute(predictions=[pred], references=[ref]) for pred, ref in zip(predictions, references)]\n",
        "\n",
        "for i, score in enumerate(rouge_scores):\n",
        "    print(f\"ROUGE scores for Question {i + 1}:\")\n",
        "    print(f\"ROUGE-1: {score['rouge1'].mid.fmeasure:.4f}\")\n",
        "    print(f\"ROUGE-2: {score['rouge2'].mid.fmeasure:.4f}\")\n",
        "    print(f\"ROUGE-L: {score['rougeL'].mid.fmeasure:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqtbtIrNZIr6",
        "outputId": "72a01560-b777-4463-cc99-76b6ecd73ff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What are the main techniques used in machine learning?\n",
            "Prompt: Based on the context, answer the following question:\n",
            "Answer: supervised learning, unsupervised learning, and reinforcement learning\n",
            "\n",
            "Question: What are the main techniques used in machine learning?\n",
            "Prompt: Using the provided context, respond to this question:\n",
            "Answer: supervised learning, unsupervised learning, and reinforcement learning\n",
            "\n",
            "Question: What are the main techniques used in machine learning?\n",
            "Prompt: Given the context, what is the answer to the question below?\n",
            "Answer: supervised learning, unsupervised learning, and reinforcement learning\n",
            "\n",
            "Question: How does supervised learning differ from unsupervised learning?\n",
            "Prompt: Based on the context, answer the following question:\n",
            "Answer: finding hidden patterns in unlabeled data\n",
            "\n",
            "Question: How does supervised learning differ from unsupervised learning?\n",
            "Prompt: Using the provided context, respond to this question:\n",
            "Answer: finding hidden patterns in unlabeled data\n",
            "\n",
            "Question: How does supervised learning differ from unsupervised learning?\n",
            "Prompt: Given the context, what is the answer to the question below?\n",
            "Answer: finding hidden patterns in unlabeled data\n",
            "\n",
            "Question: What is the purpose of reinforcement learning?\n",
            "Prompt: Based on the context, answer the following question:\n",
            "Answer: an agent learns to make decisions by receiving rewards or penalties\n",
            "\n",
            "Question: What is the purpose of reinforcement learning?\n",
            "Prompt: Using the provided context, respond to this question:\n",
            "Answer: make decisions by receiving rewards or penalties\n",
            "\n",
            "Question: What is the purpose of reinforcement learning?\n",
            "Prompt: Given the context, what is the answer to the question below?\n",
            "Answer: an agent learns to make decisions by receiving rewards or penalties\n",
            "\n",
            "ROUGE scores for Question 1:\n",
            "ROUGE-1: 0.7778\n",
            "ROUGE-2: 0.7500\n",
            "ROUGE-L: 0.7778\n",
            "ROUGE scores for Question 2:\n",
            "ROUGE-1: 0.3478\n",
            "ROUGE-2: 0.1905\n",
            "ROUGE-L: 0.3478\n",
            "ROUGE scores for Question 3:\n",
            "ROUGE-1: 0.4000\n",
            "ROUGE-2: 0.1111\n",
            "ROUGE-L: 0.3000\n"
          ]
        }
      ]
    }
  ]
}